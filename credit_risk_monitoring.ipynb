{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b7ac15-91dd-4242-9cef-89195c83425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliottbotwick/anaconda3/envs/tru1220/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import shap\n",
    "import truera\n",
    "from truera_qii import qii\n",
    "from truera_qii.qii.explainers import tree, linear\n",
    "from truera.client.ingestion import add_data, ColumnSpec, ModelOutputContext\n",
    "from truera.client.truera_workspace import TrueraWorkspace\n",
    "from truera.client.truera_authentication import BasicAuthentication, TokenAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b475c9-1f6c-4fc8-ac33-0f02b2644f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_dirname = 'datasplits'\n",
    "dc_dirname = 'dc_v1'\n",
    "split_names = [i for i in os.listdir(os.path.join(datasplit_dirname, dc_dirname)) if i.startswith('201') and len(i)==6]\n",
    "data = {}\n",
    "for i in split_names:\n",
    "    data[i] = {\n",
    "        'data': pd.read_csv(os.path.join(datasplit_dirname, dc_dirname, i, f'data_{i}.csv')),\n",
    "        'data_raw': pd.read_csv(os.path.join(datasplit_dirname, dc_dirname, i, f'data_raw_{i}.csv')),\n",
    "        'label': pd.read_csv(os.path.join(datasplit_dirname, dc_dirname, i, f'label_{i}.csv'), header=None)\n",
    "    }\n",
    "\n",
    "    \n",
    "#Define train data    \n",
    "train_post = pd.concat([data.get('2018Q1').get('data'), data.get('2018Q2').get('data'), \n",
    "                        data.get('2018Q3').get('data'), data.get('2018Q4').get('data')]).reset_index(drop=True)\n",
    "\n",
    "train_pre = pd.concat([data.get('2018Q1').get('data_raw'), data.get('2018Q2').get('data_raw'), \n",
    "                       data.get('2018Q3').get('data_raw'), data.get('2018Q4').get('data_raw')]).reset_index(drop=True)\n",
    "\n",
    "train_labels =  pd.concat([data.get('2018Q1').get('label'), data.get('2018Q2').get('label'), \n",
    "                       data.get('2018Q3').get('label'), data.get('2018Q4').get('label')]).reset_index(drop=True)\n",
    "\n",
    "#Define prod data\n",
    "prod_post = pd.concat([data.get('2016Q3').get('data'), data.get('2017Q4').get('data'),\n",
    "                        data.get('2017Q1').get('data'), data.get('2017Q2').get('data'), \n",
    "                        data.get('2017Q3').get('data'), data.get('2017Q4').get('data')]).reset_index(drop=True)\n",
    "\n",
    "prod_pre = pd.concat([data.get('2016Q3').get('data_raw'), data.get('2016Q4').get('data_raw'),\n",
    "                       data.get('2017Q1').get('data_raw'), data.get('2017Q2').get('data_raw'), \n",
    "                       data.get('2017Q3').get('data_raw'), data.get('2017Q4').get('data_raw')]).reset_index(drop=True)\n",
    "\n",
    "prod_labels =  pd.concat([data.get('2016Q3').get('label'), data.get('2016Q4').get('label'),\n",
    "                       data.get('2017Q1').get('label'), data.get('2017Q2').get('label'), \n",
    "                       data.get('2017Q3').get('label'), data.get('2017Q4').get('label')]).reset_index(drop=True)\n",
    "\n",
    "#Cast bool vars to float\n",
    "train_pre['debt_settlement_flag']=train_pre['debt_settlement_flag'].astype(float)\n",
    "prod_pre['debt_settlement_flag']=prod_pre['debt_settlement_flag'].astype(float)\n",
    "\n",
    "#Add labels to pre data dfs\n",
    "prod_pre['label'] = prod_labels\n",
    "train_pre['label'] = train_labels\n",
    "\n",
    "#Resample prod data\n",
    "prod_pre = prod_pre[prod_pre.label==1].append(prod_pre[prod_pre.label==0].sample(n=32014, random_state=1))\n",
    "prod_pre = prod_pre.sample(n=len(prod_pre), random_state=2)\n",
    "\n",
    "#Filter prod post data to match pre data and reset indexes\n",
    "prod_post = prod_post.filter(items=prod_pre.index, axis=0)\n",
    "prod_pre.reset_index(inplace=True, drop=True)\n",
    "prod_post.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Define list of pre data columns\n",
    "pre_transform_cols = prod_pre.drop(\"label\", axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c357a6ed-b1fc-4a91-bae9-c474a158f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define feature map\n",
    "FEATURE_MAP = {}\n",
    "for post in train_post.columns:\n",
    "    mapped = None\n",
    "    for pre in train_pre.columns:\n",
    "        if post.startswith(pre) and (mapped is None or len(mapped) < len(pre)):\n",
    "            mapped = pre\n",
    "    if mapped not in FEATURE_MAP:\n",
    "        FEATURE_MAP[mapped] = []\n",
    "    FEATURE_MAP[mapped].append(train_post.columns.get_loc(post))\n",
    "#Define categorical feature list    \n",
    "catFeats = list(train_pre.columns[train_pre.dtypes == 'O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc23d62-7d9e-446e-a0d1-61cacaf7b9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Model\n",
      "XGB Train Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79     76017\n",
      "           1       0.41      0.71      0.52     21902\n",
      "\n",
      "    accuracy                           0.71     97919\n",
      "   macro avg       0.66      0.71      0.66     97919\n",
      "weighted avg       0.79      0.71      0.73     97919\n",
      "\n",
      "XGB Prod Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68     32014\n",
      "           1       0.65      0.68      0.67     29674\n",
      "\n",
      "    accuracy                           0.67     61688\n",
      "   macro avg       0.67      0.67      0.67     61688\n",
      "weighted avg       0.67      0.67      0.67     61688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build XGB pipeline\n",
    "print(\"Training XGBoost Model\")\n",
    "scale_weight = train_labels.value_counts()[0]/train_labels.value_counts()[1]\n",
    "xgb = XGBClassifier(booster = \"gbtree\", n_estimators=25, max_depth=4, scale_pos_weight = scale_weight, random_state=1)\n",
    "xgb.fit(train_post, train_pre.label)\n",
    "\n",
    "#Get predictions\n",
    "xgb_train_preds = xgb.predict(train_post)\n",
    "xgb_prod_preds = xgb.predict(prod_post)\n",
    "\n",
    "print(\"XGB Train Performance:\")\n",
    "print(classification_report(train_pre.label, xgb_train_preds))\n",
    "\n",
    "print(\"XGB Prod Performance:\")\n",
    "print(classification_report(prod_pre.label, xgb_prod_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7996f4e8-9461-4547-9375-399ba6de57ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Model\n",
      "RF Train Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     76017\n",
      "           1       1.00      0.92      0.96     21902\n",
      "\n",
      "    accuracy                           0.98     97919\n",
      "   macro avg       0.99      0.96      0.97     97919\n",
      "weighted avg       0.98      0.98      0.98     97919\n",
      "\n",
      "RF Prod Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72     32014\n",
      "           1       0.82      0.28      0.41     29674\n",
      "\n",
      "    accuracy                           0.62     61688\n",
      "   macro avg       0.70      0.61      0.57     61688\n",
      "weighted avg       0.70      0.62      0.57     61688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Random Forest Model\")\n",
    "rf = RandomForestClassifier(n_estimators = 10, random_state=1)\n",
    "rf.fit(train_post, train_pre.label)\n",
    "#Get predictions\n",
    "rf_train_preds = rf.predict(train_post)\n",
    "rf_prod_preds = rf.predict(prod_post)\n",
    "\n",
    "print(\"RF Train Performance:\")\n",
    "print(classification_report(train_pre.label, rf_train_preds))\n",
    "\n",
    "print(\"RF Prod Performance:\")\n",
    "print(classification_report(prod_pre.label, rf_prod_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c56e3c5-e629-4f50-97fd-39f8aa7712b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb train AUC 0.7121436261619323\n",
      "xgb prod AUC 0.6718634692068463\n",
      "rf train AUC 0.959391926035721\n",
      "rf prod AUC 0.6101524037520165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"xgb train AUC\", roc_auc_score(train_pre.label, xgb_train_preds))\n",
    "print(\"xgb prod AUC\", roc_auc_score(prod_pre.label, xgb_prod_preds))\n",
    "print(\"rf train AUC\",roc_auc_score(train_pre.label, rf_train_preds))\n",
    "print(\"rf prod AUC\",roc_auc_score(prod_pre.label, rf_prod_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7095ca5b-a640-4c58-af53-59ff905c820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing FI data for xgb train\n",
      "Found existing FI data for xgb prod\n",
      "Found existing FI data for rf train\n",
      "Found existing FI data for rf prod\n"
     ]
    }
   ],
   "source": [
    "#Compute feature influences if not already computed for train/prod for each model\n",
    "try: \n",
    "    xgb_fi_train = pd.read_csv(\"FI_probits/xgb_train_FI.csv\")\n",
    "    print(\"Found existing FI data for xgb train\")\n",
    "except:\n",
    "    print(\"Computing FIs and writing locally (will take a while)\")\n",
    "    xgb_explainer = qii.explainers.tree.TreeExplainer(xgb, shap.sample(train_post,100),  \n",
    "                                                      pretransform_features=pre_transform_cols, feature_map=FEATURE_MAP, model_output=\"probability\")\n",
    "    xgb_fi_train = pd.DataFrame(xgb_explainer.truera_qii_values(train_post, train_pre.label), columns = pre_transform_cols)\n",
    "    xgb_fi_train.to_csv(\"FI_probits/xgb_train_FI.csv\",index=False) \n",
    "    \n",
    "try: \n",
    "    xgb_fi_prod = pd.read_csv(\"FI_probits/xgb_prod_FI.csv\")\n",
    "    print(\"Found existing FI data for xgb prod\")\n",
    "except:\n",
    "    print(\"Computing FIs and writing locally (will take a while)\")\n",
    "    xgb_explainer = qii.explainers.tree.TreeExplainer(xgb, shap.sample(train_post,100),  \n",
    "                                                  pretransform_features=pre_transform_cols, feature_map=FEATURE_MAP, model_output=\"probability\")\n",
    "    xgb_fi_prod = pd.DataFrame(xgb_explainer.truera_qii_values(prod_post, prod_pre.label), columns = prod_pre.columns)\n",
    "    xgb_fi_prod.to_csv(\"FI_probits/xgb_prod_FI.csv\",index=False)\n",
    "    \n",
    "try: \n",
    "    rf_fi_train = pd.read_csv(\"FI_probits/rf_train_FI.csv\")\n",
    "    print(\"Found existing FI data for rf train\")\n",
    "except:\n",
    "    print(\"Computing FIs and writing locally (will take a while)\")\n",
    "    rf_explainer = qii.explainers.tree.TreeExplainer(rf, shap.sample(train_post, 100), \n",
    "                                                 pretransform_features=pre_transform_cols, feature_map=FEATURE_MAP, model_output=\"probability\")\n",
    "    rf_fi_train = pd.DataFrame(rf_explainer.truera_qii_values(train_post, label), columns = train_pre.columns)\n",
    "    rf_fi_train.to_csv(\"FI_probits/rf_train_FI.csv\",index=False)\n",
    "    \n",
    "\n",
    "try: \n",
    "    rf_fi_prod = pd.read_csv(\"FI_probits/rf_prod_FI.csv\")\n",
    "    print(\"Found existing FI data for rf prod\")\n",
    "except:\n",
    "    print(\"Computing FIs and writing locally (will take a while)\")\n",
    "    rf_explainer = qii.explainers.tree.TreeExplainer(rf, shap.sample(train_post, 100), \n",
    "                                                     pretransform_features=pre_transform_cols, feature_map=FEATURE_MAP, model_output=\"probability\")\n",
    "\n",
    "    rf_fi_prod = pd.DataFrame(rf_explainer.truera_qii_values(prod_post, prod_pre.label), columns = pre_transform_cols)\n",
    "    rf_fi_prod.to_csv(\"FI_probits/rf_prod_FI.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce14c3cf-98c4-4eb0-ab24-df69b03c102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute prediction probabilities for models\n",
    "rf_train_preds = rf.predict_proba(train_post)[:,1]\n",
    "xgb_train_preds = xgb.predict_proba(train_post)[:,1]\n",
    "\n",
    "rf_prod_preds = rf.predict_proba(prod_post)[:,1]\n",
    "xgb_prod_preds = xgb.predict_proba(prod_post)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23844fe7-6e91-4e24-a38b-055c7d54358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename FI columns\n",
    "rf_fi_train.rename(columns={c: f\"{c}_truera-qii_influence\" for c in rf_fi_train.columns}, inplace=True)\n",
    "xgb_fi_train.rename(columns={c: f\"{c}_truera-qii_influence\" for c in xgb_fi_train.columns}, inplace=True)\n",
    "\n",
    "rf_fi_prod.rename(columns={c: f\"{c}_truera-qii_influence\" for c in rf_fi_prod.columns}, inplace=True)\n",
    "xgb_fi_prod.rename(columns={c: f\"{c}_truera-qii_influence\" for c in xgb_fi_prod.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc4ebe4-7d01-4dd3-ad0b-0588a6c98f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensure all train dfs have same shape\n",
      "(97919, 37) (97919, 37) (97919, 37) (97919, 37)\n",
      "Ensure all prod dfs have same shape\n",
      "(61688, 37) (61688, 37) (61688, 37) (61688, 37)\n",
      "ensure id dtypes are the same\n",
      "object object\n",
      "RF dtype check pass:  True\n",
      "RF dtype check pass:  True\n",
      "Prediction Column: prediction\n",
      "Label Column: label\n",
      "Timestamp Column: timestamp\n",
      "ID Column: id\n"
     ]
    }
   ],
   "source": [
    "#Set up train and prod timestamps\n",
    "train_pre['timestamp'] = pd.Series(train_pre.index).apply(lambda x: datetime.datetime(2023, 1, 1)+datetime.timedelta(minutes=x*2.25))\n",
    "end_train = train_pre.timestamp.max()+datetime.timedelta(minutes=4.5)\n",
    "prod_pre['timestamp'] = pd.Series(prod_pre.index).apply(lambda x: end_train+datetime.timedelta(minutes=x*2.5))\n",
    "\n",
    "#Seperate data frames for each model\n",
    "rf_train = train_pre.copy()\n",
    "xgb_train = train_pre.copy()\n",
    "\n",
    "rf_prod = prod_pre.copy()\n",
    "xgb_prod= prod_pre.copy()\n",
    "\n",
    "#Add Ids to pre data\n",
    "rf_train['id'] = pd.Series(train_pre.index).apply(lambda x: \"rf_train_\"+str(x))\n",
    "xgb_train['id'] = pd.Series(train_pre.index).apply(lambda x: \"xgb_train_\"+str(x))\n",
    "\n",
    "rf_prod['id'] = pd.Series(prod_pre.index).apply(lambda x: \"rf_prod_\"+str(x))\n",
    "xgb_prod['id'] = pd.Series(prod_pre.index).apply(lambda x: \"xgb_prod_\"+str(x))\n",
    "\n",
    "#Add IDs to feature influence data\n",
    "rf_fi_train['id'] = rf_train.id\n",
    "rf_fi_prod['id'] = rf_prod.id\n",
    "\n",
    "xgb_fi_train['id'] = xgb_train.id\n",
    "xgb_fi_prod['id'] = xgb_prod.id\n",
    "\n",
    "#Add predictions to dfs\n",
    "rf_train['prediction'] = np.hstack([rf_train_preds])\n",
    "xgb_train['prediction'] = np.hstack([xgb_train_preds])\n",
    "\n",
    "rf_prod['prediction'] = np.hstack([rf_prod_preds])\n",
    "xgb_prod['prediction'] = np.hstack([xgb_prod_preds])\n",
    "\n",
    "#Add labels to train (already exist in prod)\n",
    "rf_train['label'] = train_labels\n",
    "xgb_train['label'] = train_labels\n",
    "\n",
    "print(\"Ensure all train dfs have same shape\")\n",
    "print(xgb_train.drop([\"label\",\"prediction\", \"timestamp\"], axis=1).shape, rf_train.drop([\"label\",\"prediction\", \"timestamp\"], axis=1).shape, rf_fi_train.shape, xgb_fi_train.shape)\n",
    "\n",
    "print(\"Ensure all prod dfs have same shape\")\n",
    "print(xgb_prod.drop([\"label\",\"prediction\", \"timestamp\"], axis=1).shape, rf_prod.drop([\"label\",\"prediction\", \"timestamp\"], axis=1).shape, rf_fi_prod.shape, xgb_fi_prod.shape)\n",
    "\n",
    "print(\"ensure id dtypes are the same\")\n",
    "print(rf_train.id.dtypes, rf_prod.id.dtypes)\n",
    "\n",
    "print(\"RF dtype check pass: \", sum(rf_train.dtypes == rf_prod.dtypes)==rf_train.shape[1])\n",
    "print(\"RF dtype check pass: \", sum(xgb_train.dtypes == xgb_prod.dtypes)==xgb_train.shape[1])\n",
    "\n",
    "#Define and print key columns\n",
    "prediction_col = \"prediction\"\n",
    "label_col = \"label\"\n",
    "timestamp_col = \"timestamp\"\n",
    "id_col = \"id\"\n",
    "pre_cols = list(rf_train.drop([\"id\",\"label\",\"prediction\", \"timestamp\"], axis=1).columns)\n",
    "fi_cols = list(rf_fi_train.drop([\"id\"], axis=1).columns)\n",
    "\n",
    "print(\"Prediction Column:\", prediction_col)\n",
    "print(\"Label Column:\", label_col)\n",
    "print(\"Timestamp Column:\", timestamp_col)\n",
    "print(\"ID Column:\", id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f51a20-f36d-420d-b9cf-91cd3f057d0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2515016895.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [11]\u001b[0;36m\u001b[0m\n\u001b[0;31m    token = <INSERT TOKEN GENERATED FROM UI>\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Start Truera Ingestion\n",
    "ingestion_start = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "\n",
    "#See docs for generating token here - https://docs.truera.com/1.40/public/diagnostics-quickstart/#connecting-to-truera\n",
    "token = <INSERT TOKEN GENERATED FROM UI> \n",
    "\n",
    "CONNECTION_STRING = \"https://app.truera.net/\"\n",
    "\n",
    "\n",
    "### CHECK YOUR TOKEN/CONNECTION STRING!!!!\n",
    "\n",
    "auth = TokenAuthentication(token)\n",
    "tru = TrueraWorkspace(CONNECTION_STRING, auth, verify_cert=False)\n",
    "\n",
    "#Specify to use truera server for remote compute\n",
    "tru.set_environment(\"remote\")\n",
    "\n",
    "PROJECT_NAME = <INSERT PROJECT NAME HERE>\n",
    "print(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b481fffb-7166-45c3-9a05-9bf1f7489d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new project\n",
    "try: \n",
    "    tru.add_project(PROJECT_NAME, score_type=\"probits\")\n",
    "    print(\"Adding new project\")\n",
    "except:\n",
    "    print(\"Setting existing project\")\n",
    "    tru.set_project(PROJECT_NAME)\n",
    "    \n",
    "#Add rf data collection\n",
    "DATA_COLLECTION_NAME=\"Credit-risk-rf\"\n",
    "\n",
    "try:\n",
    "    tru.add_data_collection(DATA_COLLECTION_NAME)\n",
    "    print('Adding new data colleciton')\n",
    "except:\n",
    "    print('Setting existing data collection')\n",
    "    tru.set_data_collection(DATA_COLLECTION_NAME)\n",
    "    \n",
    "#Upload random forest model\n",
    "tru.add_model('Random_Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b793767-1614-44c4-a31d-5f5bdffc3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Define column_spec\n",
    "column_spec = ColumnSpec(\n",
    "        id_col_name=id_col,\n",
    "        timestamp_col_name = timestamp_col,\n",
    "        prediction_col_names=prediction_col,\n",
    "        pre_data_col_names=pre_cols,\n",
    "        label_col_names=label_col\n",
    ")\n",
    "\n",
    "\n",
    "#Define model context and add data\n",
    "tru.set_model('Random_Forest')\n",
    "\n",
    "model_context = ModelOutputContext(model_name = tru._get_current_active_model_name(),\n",
    "                                     score_type=tru._get_score_type())\n",
    "\n",
    "print(\"Adding RF Train Data\")\n",
    "add_data(\n",
    "    tru.remote_tru,\n",
    "    rf_train,\n",
    "    split_name=\"train\",\n",
    "    column_spec=column_spec,\n",
    "    model_output_context=model_context\n",
    ")\n",
    "\n",
    "while len(tru.get_data_splits())==0:\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28975250-8221-45f3-9426-25346d1021c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Define column_spec for FIs\n",
    "tru.set_model('Random_Forest')\n",
    "rf_fi_start = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "column_spec_FI = ColumnSpec(\n",
    "        id_col_name=\"id\",\n",
    "        feature_influence_col_names = fi_cols\n",
    ")\n",
    "\n",
    "model_context_FI = ModelOutputContext(\n",
    "    model_name = tru._get_current_active_model_name(),\n",
    "    score_type=tru._get_score_type(),\n",
    "    influence_type=\"truera-qii\", \n",
    "    background_split_name=\"train\"\n",
    ")\n",
    "\n",
    "print(\"Adding RF Train FI data\")\n",
    "add_data(\n",
    "    tru.remote_tru,\n",
    "    rf_fi_train,\n",
    "    split_name=\"train\",\n",
    "    column_spec=column_spec_FI,\n",
    "    model_output_context=model_context_FI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dfe93-4695-4a85-bdc3-6d15354fb0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#merge prod data together\n",
    "rf_prod_all = rf_prod.merge(rf_fi_prod.drop('id', axis=1), left_index=True, right_index=True)\n",
    "\n",
    "#Add prod data with feature influences\n",
    "rf_prod_start = datetime.datetime.now().replace(microsecond=0)\n",
    "#Define column_spec\n",
    "column_spec_prod = ColumnSpec(\n",
    "        id_col_name=id_col,\n",
    "        timestamp_col_name = timestamp_col,\n",
    "        prediction_col_names=prediction_col,\n",
    "        pre_data_col_names=pre_cols,\n",
    "        feature_influence_col_names = fi_cols,\n",
    "        label_col_names=label_col\n",
    ")\n",
    "\n",
    "model_context_prod = ModelOutputContext(\n",
    "    model_name = tru._get_current_active_model_name(),\n",
    "    score_type=tru._get_score_type(),\n",
    "    influence_type=\"truera-qii\", \n",
    "    background_split_name=\"train\"\n",
    ")\n",
    "\n",
    "print(\"Adding RF prod data\")\n",
    "\n",
    "tru.add_production_data(\n",
    "    data=rf_prod_all,\n",
    "    column_spec=column_spec_prod,\n",
    "    model_output_context=model_context_prod\n",
    ")\n",
    "rf_prod_end = datetime.datetime.now().replace(microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ed1e0-49c0-49d9-887f-24855330641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add xgboost data collection\n",
    "DATA_COLLECTION_NAME=\"Credit-risk-XGB\"\n",
    "\n",
    "try:\n",
    "    tru.add_data_collection(DATA_COLLECTION_NAME)\n",
    "    print('Adding new data colleciton')\n",
    "except:\n",
    "    print('Setting existing data collection')\n",
    "    tru.set_data_collection(DATA_COLLECTION_NAME)\n",
    "    \n",
    "#Upload xgboost model\n",
    "tru.add_model('XGBoost')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54960e2f-f9a0-4578-a9e5-ef32e1a1f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Define column_spec\n",
    "column_spec = ColumnSpec(\n",
    "        id_col_name=id_col,\n",
    "        timestamp_col_name = timestamp_col,\n",
    "        prediction_col_names=prediction_col,\n",
    "        pre_data_col_names=pre_cols,\n",
    "        label_col_names=label_col\n",
    ")\n",
    "\n",
    "#Define model context and add data\n",
    "tru.set_model('XGBoost')\n",
    "\n",
    "model_context = ModelOutputContext(model_name = tru._get_current_active_model_name(),\n",
    "                                     score_type=tru._get_score_type())\n",
    "\n",
    "print(\"Adding xgboost train data\")\n",
    "add_data(\n",
    "    tru.remote_tru,\n",
    "    xgb_train,\n",
    "    split_name=\"train\",\n",
    "    column_spec=column_spec,\n",
    "    model_output_context=model_context\n",
    ")\n",
    "\n",
    "while len(tru.get_data_splits())==0:\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09f532-6e23-4747-9359-eaf0dab77b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Add xgboost train FI data\n",
    "xgb_fi_start = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "tru.set_model('XGBoost')\n",
    "\n",
    "column_spec_FI = ColumnSpec(\n",
    "        id_col_name=\"id\",\n",
    "        feature_influence_col_names = fi_cols\n",
    ")\n",
    "\n",
    "model_context_FI = ModelOutputContext(\n",
    "    model_name = tru._get_current_active_model_name(),\n",
    "    score_type=tru._get_score_type(),\n",
    "    influence_type=\"truera-qii\", \n",
    "    background_split_name=\"train\"\n",
    ")\n",
    "print(\"Adding xgboost train FI data\")\n",
    "add_data(\n",
    "    tru.remote_tru,\n",
    "    xgb_fi_train,\n",
    "    split_name=\"train\",\n",
    "    column_spec=column_spec_FI,\n",
    "    model_output_context=model_context_FI\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80434eeb-37e1-4e4f-b066-5a23f90d809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_prod_all = xgb_prod.merge(xgb_fi_prod.drop('id', axis=1), left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "#Add prod data with feature influences\n",
    "xgb_prod_start = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "#Define column_spec\n",
    "column_spec_prod = ColumnSpec(\n",
    "        id_col_name=id_col,\n",
    "        timestamp_col_name = timestamp_col,\n",
    "        prediction_col_names=prediction_col,\n",
    "        pre_data_col_names=pre_cols,\n",
    "        feature_influence_col_names = fi_cols,\n",
    "        label_col_names=label_col\n",
    ")\n",
    "\n",
    "model_context_prod = ModelOutputContext(\n",
    "    model_name = tru._get_current_active_model_name(),\n",
    "    score_type=tru._get_score_type(),\n",
    "    influence_type=\"truera-qii\", \n",
    "    background_split_name=\"train\"\n",
    ")\n",
    "\n",
    "print(\"Adding xgboost prod data\")\n",
    "\n",
    "tru.add_production_data(\n",
    "    data=xgb_prod_all,\n",
    "    column_spec=column_spec_prod,\n",
    "    model_output_context=model_context_prod\n",
    ")\n",
    "xgb_prod_end = datetime.datetime.now().replace(microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea815f9a-9478-4d93-a0ef-cdd71a6bd411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOK COMPLETE 2023-10-20 14:38:58\n"
     ]
    }
   ],
   "source": [
    "#Define segment groups and add\n",
    "grade_segment_defintions = {\"grade_a\": \"grade = 'A'\",\n",
    " \"grade_b\": \"grade = 'B'\",\n",
    " \"grade_c\": \"grade = 'C'\",\n",
    " \"grade_d\": \"grade = 'D'\",\n",
    " \"grades_efg\": \"grade='E' OR grade='F' OR grade='G'\"\n",
    "                            \n",
    "}\n",
    "\n",
    "tru.add_segment_group(\"grade\", grade_segment_defintions)\n",
    "\n",
    "\n",
    "\n",
    "print(\"NOTEBOOK COMPLETE\", datetime.datetime.now().replace(microsecond=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ffde4-7a23-415e-bc0d-54d0420fe1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tru1220",
   "language": "python",
   "name": "tru1220"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
